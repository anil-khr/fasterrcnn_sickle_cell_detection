{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anil\\anaconda3\\envs\\fasterrcnn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_rcnn_od.utils.comman import custom_collate, Averager, SaveBestModel, save_loss_plot, save_model, CustDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class training:\n",
    "    \n",
    "    global train_itr\n",
    "    global train_loss_list\n",
    "    DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def base_model(self):\n",
    "        return torch.load(r'C:\\Users\\anil\\Downloads\\faster_rcnn_od\\fasterrcnn_sickle_cell_detection\\artifacts\\prepare_base_model\\base_model.pt')\n",
    "    \n",
    "    def train_start(self):\n",
    "        \n",
    "        # print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "        # print(f\"Number of validation samples: {len(valid_dataset)}\\n\")\n",
    "        # initialize the model and move to the computation device\n",
    "        model = self.base_model()\n",
    "        model = model.to(self.DEVICE)\n",
    "        # get the model parameters\n",
    "        params = [p for p in model.parameters() if p.requires_grad]\n",
    "        # define the optimizer\n",
    "        optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "        # initialize the Averager class\n",
    "        train_loss_hist = Averager()\n",
    "        val_loss_hist = Averager()\n",
    "        self.train_itr = 1\n",
    "        self.val_itr = 1\n",
    "        # train and validation loss lists to store loss values of all...\n",
    "        # ... iterations till ena and plot graphs for all iterations\n",
    "        # name to save the trained model with\n",
    "        MODEL_NAME = 'model'\n",
    "        # whether to show transformed images from data loader or not\n",
    "        save_best_model = SaveBestModel()\n",
    "        # start the training epochs\n",
    "        NUM_EPOCHS = 1\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            print(f\"\\nEPOCH {epoch+1} of {NUM_EPOCHS}\")\n",
    "            # reset the training and validation loss histories for the current epoch\n",
    "            train_loss_hist.reset()\n",
    "            val_loss_hist.reset()\n",
    "            # start timer and carry out training and validation\n",
    "            start = time.time()\n",
    "            train_loss, loss_train = self.train(self.train_data_loader('train_loder.pt'), model, optimizer)\n",
    "            val_loss, loss_val = self.validate(self.train_data_loader('val_loader.pt'), model)\n",
    "            train_loss_hist.send(loss_train)\n",
    "            train_loss_hist.send(loss_val)\n",
    "            print(f\"Epoch #{epoch+1} train loss: {train_loss_hist.value:.3f}\")   \n",
    "            print(f\"Epoch #{epoch+1} validation loss: {val_loss_hist.value:.3f}\")   \n",
    "            end = time.time()\n",
    "            print(f\"Took {((end - start) / 60):.3f} minutes for epoch {epoch}\")\n",
    "            # save the best model till now if we have the least loss in the...\n",
    "            # ... current epoch\n",
    "            save_best_model(\n",
    "                val_loss_hist.value, epoch, model, optimizer\n",
    "            )\n",
    "            # save the current epoch model\n",
    "            save_model(epoch, model, optimizer)\n",
    "            # save loss plot\n",
    "            OUT_DIR = r'C:\\Users\\anil\\Downloads\\faster_rcnn_od\\fasterrcnn_sickle_cell_detection\\artifacts\\transformed_data'\n",
    "            save_loss_plot(OUT_DIR, train_loss, val_loss)\n",
    "            \n",
    "            # sleep for 5 seconds after each epoch\n",
    "            time.sleep(5)\n",
    "        \n",
    "    def train_data_loader(self, file_name):  \n",
    "        path = r'C:\\Users\\anil\\Downloads\\faster_rcnn_od\\fasterrcnn_sickle_cell_detection\\artifacts\\transformed_data'\n",
    "        path_tr = os.path.join(path, file_name)\n",
    "        data = torch.load(path_tr)\n",
    "        for i in data:\n",
    "            imgs = []\n",
    "            targets = []\n",
    "            for d in i:\n",
    "                imgs.append(d[0])\n",
    "                targ = {}\n",
    "                targ['boxes'] = d[1]['boxes']#.to(device)\n",
    "                targ['labels'] = d[1]['label']#.to(device)\n",
    "                targets.append(targ)\n",
    "        return (targets, imgs)\n",
    "        \n",
    "    def train(self,train_data_loader, model, optimizer):\n",
    "        \n",
    "        print('Training')\n",
    "        global train_itr\n",
    "        global train_loss_list\n",
    "        train_loss_list = []\n",
    "        \n",
    "        # initialize tqdm progress bar\n",
    "        prog_bar = tqdm(train_data_loader, total=len(train_data_loader))\n",
    "        targets, images = train_data_loader\n",
    "        for i, data in enumerate(prog_bar):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_dict = model(images, targets)\n",
    "            print(loss_dict)\n",
    "            losses = sum(loss for loss in loss_dict[0].values())\n",
    "            loss_value = losses.item()\n",
    "            train_loss_list.append(loss_value)\n",
    "            train_loss_hist = Averager()\n",
    "            train_loss_hist.send(loss_value)\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            self.train_itr += 1\n",
    "            \n",
    "        \n",
    "            # update the loss value beside the progress bar for each iteration\n",
    "            prog_bar.set_description(desc=f\"Loss: {loss_value:.4f}\")\n",
    "        return train_loss_list, loss_value\n",
    "    \n",
    "    \n",
    "    def validate(self, valid_data_loader, model ):\n",
    "        print('Validating')\n",
    "        global val_itr\n",
    "        global val_loss_list\n",
    "        val_loss_list = []\n",
    "        \n",
    "        # initialize tqdm progress bar\n",
    "        prog_bar = tqdm(valid_data_loader, total=len(valid_data_loader))\n",
    "        \n",
    "        for i, data in enumerate(prog_bar):\n",
    "            targets, images  = valid_data_loader\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict[0].values())\n",
    "            loss_value = losses.item()\n",
    "            val_loss_list.append(loss_value)\n",
    "            \n",
    "           # val_loss_hist.send(loss_value)\n",
    "            self.val_itr += 1\n",
    "            # update the loss value beside the progress bar for each iteration\n",
    "            prog_bar.set_description(desc=f\"Loss: {loss_value:.4f}\")\n",
    "        return val_loss_list, loss_value\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anil\\Downloads\\faster_rcnn_od\\fasterrcnn_sickle_cell_detection\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\anil\\Downloads\\faster_rcnn_od\\fasterrcnn_sickle_cell_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anil\\anaconda3\\envs\\fasterrcnn\\lib\\site-packages\\torch\\serialization.py:799: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 of 1\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]code/__torch__/torchvision/models/detection/faster_rcnn.py:103: UserWarning: RCNN always returns a (Losses, Detections) tuple in scripting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'loss_classifier': tensor(1.8546, grad_fn=<NllLossBackward0>), 'loss_box_reg': tensor(0.7639, grad_fn=<DivBackward1>), 'loss_objectness': tensor(6.1155, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'loss_rpn_box_reg': tensor(0.1742, grad_fn=<DivBackward1>)}, [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 8.9082:  50%|█████     | 1/2 [00:08<00:08,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'loss_classifier': tensor(1.5814, grad_fn=<NllLossBackward0>), 'loss_box_reg': tensor(0.7030, grad_fn=<DivBackward1>), 'loss_objectness': tensor(1.1017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'loss_rpn_box_reg': tensor(0.1617, grad_fn=<DivBackward1>)}, [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.5479: 100%|██████████| 2/2 [00:18<00:00,  9.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.6148: 100%|██████████| 2/2 [00:05<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 train loss: 3.581\n",
      "Epoch #1 validation loss: 0.000\n",
      "Took 0.750 minutes for epoch 0\n",
      "\n",
      "Best validation loss: 0\n",
      "\n",
      "Saving best model for epoch: 1\n",
      "\n",
      "SAVING PLOTS COMPLETE...\n"
     ]
    }
   ],
   "source": [
    "trai = training()\n",
    "trai.train_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dam:\n",
    "    def cam(self):\n",
    "        self.a = [5]\n",
    "        \n",
    "    def bam(self):\n",
    "        print(self.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dam' object has no attribute 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m b \u001b[39m=\u001b[39m dam()\n\u001b[1;32m----> 2\u001b[0m b\u001b[39m.\u001b[39;49mbam()\n",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m, in \u001b[0;36mdam.bam\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbam\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ma)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dam' object has no attribute 'a'"
     ]
    }
   ],
   "source": [
    "b = dam()\n",
    "b.bam()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasterrcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
